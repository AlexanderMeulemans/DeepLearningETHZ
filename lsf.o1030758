Sender: LSF System <lsfadmin@lo-s4-032>
Subject: Job 1030758: <python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv> in cluster <leonhard> Exited

Job <python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv> was submitted from host <lo-login-02> by user <ameulema> in cluster <leonhard> at Fri Dec 14 12:31:59 2018
Job was executed on host(s) <20*lo-s4-032>, in queue <gpu.4h>, as user <ameulema> in cluster <leonhard> at Fri Dec 14 12:32:10 2018
</cluster/home/ameulema> was used as the home directory.
</cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ> was used as the working directory.
Started at Fri Dec 14 12:32:10 2018
Terminated at Fri Dec 14 12:38:30 2018
Results reported at Fri Dec 14 12:38:30 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   354.56 sec.
    Max Memory :                                 7847 MB
    Average Memory :                             4897.53 MB
    Total Requested Memory :                     90000.00 MB
    Delta Memory :                               82153.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                10
    Run time :                                   395 sec.
    Turnaround time :                            391 sec.

The output (if any) follows:

/cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ/helper_functions.py:55: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))
/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/PIL/Image.py:2514: DecompressionBombWarning: Image size (145486286 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  DecompressionBombWarning)
/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/PIL/Image.py:2514: DecompressionBombWarning: Image size (121684223 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  DecompressionBombWarning)
<class 'torch.LongTensor'>
<class 'torch.cuda.FloatTensor'>
Starting epoch 1 / 5
t = 100, loss = 1.3071
t = 200, loss = 1.2619
t = 300, loss = 0.8447
t = 400, loss = 1.1217
t = 500, loss = 1.3226
t = 600, loss = 1.1121
t = 700, loss = 0.8531
t = 800, loss = 1.1135
t = 900, loss = 0.7703
t = 1000, loss = 1.1660
t = 1100, loss = 1.9320
t = 1200, loss = 0.8936
t = 1300, loss = 0.5495
t = 1400, loss = 1.2669
t = 1500, loss = 0.7950
t = 1600, loss = 0.8458
t = 1700, loss = 0.4339
t = 1800, loss = 0.3543
t = 1900, loss = 1.2106
t = 2000, loss = 1.4688
t = 2100, loss = 1.6111
Traceback (most recent call last):
  File "ResNet18.py", line 165, in <module>
    results = train(model_conv, loss_fn, optimizer_conv, loader_train, loader_val, num_epochs = 5)
  File "/cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ/helper_functions.py", line 49, in train
    for t, (x, y) in enumerate(loader_train):
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 314, in __next__
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 314, in <listcomp>
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File "/cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ/Dataset.py", line 35, in __getitem__
    image = io.imread(img_name)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/skimage/io/_io.py", line 62, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/skimage/io/manage_plugins.py", line 214, in call_plugin
    return func(*args, **kwargs)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py", line 36, in imread
    im = Image.open(f)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/PIL/Image.py", line 2577, in open
    im = _open_core(fp, filename, prefix)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/PIL/Image.py", line 2568, in _open_core
    _decompression_bomb_check(im.size)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/PIL/Image.py", line 2507, in _decompression_bomb_check
    (pixels, 2 * MAX_IMAGE_PIXELS))
PIL.Image.DecompressionBombError: Image size (669000000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.
