Sender: LSF System <lsfadmin@lo-s4-007>
Subject: Job 1023894: <python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv> in cluster <leonhard> Exited

Job <python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv> was submitted from host <lo-login-02> by user <ameulema> in cluster <leonhard> at Tue Dec 11 20:30:46 2018
Job was executed on host(s) <lo-s4-007>, in queue <gpu.4h>, as user <ameulema> in cluster <leonhard> at Tue Dec 11 20:31:06 2018
</cluster/home/ameulema> was used as the home directory.
</cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ> was used as the working directory.
Started at Tue Dec 11 20:31:06 2018
Terminated at Tue Dec 11 20:31:23 2018
Results reported at Tue Dec 11 20:31:23 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ResNet18.py --data_augmentation standard --resultfile run_resnet.csv --datafolder train_reduced --infofile final_train_info.csv
------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11.54 sec.
    Max Memory :                                 2048 MB
    Average Memory :                             1450.00 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                6
    Run time :                                   40 sec.
    Turnaround time :                            37 sec.

The output (if any) follows:

<class 'torch.LongTensor'>
<class 'torch.cuda.FloatTensor'>
Starting epoch 1 / 5
Traceback (most recent call last):
  File "ResNet18.py", line 165, in <module>
    results = train(model_conv, loss_fn, optimizer_conv, loader_train, loader_val, num_epochs = 5)
  File "/cluster/home/ameulema/DeepLearningETHZ/DeepLearningETHZ/helper_functions.py", line 49, in train
    for t, (x, y) in enumerate(loader_train):
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 330, in __next__
    idx, batch = self._get_batch()
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 309, in _get_batch
    return self.data_queue.get()
  File "/cluster/apps/python/3.6.4/lib64/python3.6/multiprocessing/queues.py", line 335, in get
    res = self._reader.recv_bytes()
  File "/cluster/apps/python/3.6.4/lib64/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 227, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3075) is killed by signal: Killed.
