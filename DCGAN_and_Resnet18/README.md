
# Provided files: 

the full dataset from https://www.kaggle.com/c/painter-by-numbers/data. The csv file containing all the artist names, styles and file names for Impressionism, Realism and Romanticism (the last style will not be needed for this code) is named final_train_info_modified.csv and can be found in the folder data_info_files in our submission.


# 1) The aim of the following two files is to select specific style images with their corresponding labels in csv format

Create a directory data_info_files in you current directory, to store all csv info files about the data and labels

-make_reduced_datafile.py: takes a csv file with artist, style and file name information as input and outputs a csv file with the same data for a subset of styles only (these can be freely chosen in the "look_for" list line 20).

```
python make_reduced_datafile.py --inputfile data_info_files/train_info.csv --outpufile data_info_files/reduced_train_info.csv
```

-make_subselection_data.py takes an input file with images corresponding to the information csv file described above and outputs a file with images corresponding to the output info file of the above program.

```
python make_subselection_data.py --inputdir train --outputdir train_reduced
```



# 2) DCGAN part

Create a "data" directory in the current directory. The output of the following program should be in this folder.

-classical_data_augmentation.py: does preprocessing in order to get enough data for training the GAN. Implements following transformations: rescale, random crop, mirror, four-crop. The output size of the images is 64*64 pixels (this can be changed at the beginning of each function). The transforms are concatenated in the final "apply_transforms" function of the file.

```
python classical_data_augmentation.py --inputdir train_reduced --outputdir data/train_classically_augmented
```

The actual DCGAN code consists of the 4 files main.py, ops.py, utils.py, model.py:
the parameters can be adjusted in the file main.py. The code is a modified version of https://github.com/carpedm20/DCGAN-tensorflow where we kept the same architecture but adapted it to our own data preprocessing (see model-py and utils.py).

```
in training mode: python main.py train_classically_augmented --train
after training: python main.py --dataset train_classically_augmented
```

You should make sure that train_classically_augmented/ is in the data/ directory. And that data/ is in your current directory.
As an output: a folder samples/ is created in the current directory: it contains 100 generated files (each of them is a 8*8 grid of 64 images in total). logs/ contains the statistics that can be seen in tensorboard.


-parse_DCGAN_output.py: takes the 100 generated files (each of them is a 8*8 grid of 64 images in total) from the "samples" directory generated by the previous DCGAN algotithm and parses them into 6400 single 64*64 pixel images in the folder "augmented_dataset".

```
python parse_DCGAN_output.py
```

Recall: both data/ and data_info_files/ should be in the current directory.




# 3) Classification part 
We now use this additional data to see if it increases classification accuracy

-label_csvfile_for_augmenteddata_tobefedto_classifier.py: takes an image folder and outputs a label file with non relevant artist names (irrelevant for our task), style (chosen as input) and file name. It is used to create a label csv file for the data generated by the DCGAN.

```
python label_csvfile_for_augmenteddata_tobefedto_classifier.py --inputdir augmented_dataset --style='Impressionism' --outcsv_file=labels_for_gan_augmented_data.csv
```

Classification with Resnet18 architecture: files Resnet18.py, Dataset.py and helper_functions.py.
For the following part the data files need not be in the data/ directory but the info csv files still need to be in the data_info_files/ directory.

You have to create a "result_files" and a "working_directory" in you current directory. "result_files" will contain the accuracy values for every epoch at the end of the program run. "working_directory" contains the splits in validation, test set.

```
python Resnet18.py --data_augmentation none [or standard or extra] --resultfile result_ResNet18.csv --datafolder xxx --infofile xxx.csv --datafolder_extra xxx --infofile_extra labels_for_gan_augmented_data.csv (see detailed description for each experiment below)
```


Note about the experiments relative to the paintings:  

First we need to obtain a data file containing only Impressionistic and Realistic images, and the corresponding label file. For this run make_reduced_datafile.py as in 1) but modify the look_for list to ['Realism', 'Impressionism'] before running it. Then run make_subselection_data.py. Let us name the created folder real_and_impress/ and the file info_real_and_impress.csv

-for experiment "Resized": 
```
python Resnet18.py --data_augmentation none --resultfile result_ResNet18.csv --datafolder real_and_impress --infofile info_real_and_impress.csv
```

-for experiment "Cropped": same procedure but you have to uncomment line 74 and 121 in Resnet18.py

-experiment "Resized+GAN 0,78":  
```
python Resnet18.py --data_augmentation none --resultfile result_ResNet18.csv --datafolder real_and_impress --infofile info_real_and_impress.csv --datafolder_extra augmented_dataset --infofile_extra labels_for_gan_augmented_data.csv
```

-For other percentages of GAN data you can create a folder and copy a certain amount of data into it. And then run label_csvfile_for_augmenteddata_tobefedto_classifier.py to get a corresponding label csv file, and proceed as before.


# 4) Our contributions

- The 4 DCGAN code files main.py, ops.py, utils.py, model.py are adapted from https://github.com/carpedm20/DCGAN-tensorflow. We kept the same architecture but adapted it to our own data preprocessing (see model-py and utils.py).

- For the classification part, the files Resnet18.py, Dataset.py and helper_functions.py were adapted from https://github.com/Genoc/cs231n-final. We also extended it to accept an extra dataset and corresponding labels as input and extra data augmentation options.

- The rest of the code was created by ourselves.


























